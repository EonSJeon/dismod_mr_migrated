{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a10dd0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0b42542d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_jsonc(filepath):\n",
    "    \"\"\"Load JSONC file (JSON with comments)\"\"\"\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # Remove single-line comments (// ...)\n",
    "    content = re.sub(r'//.*?$', '', content, flags=re.MULTILINE)\n",
    "    \n",
    "    # Remove multi-line comments (/* ... */)\n",
    "    content = re.sub(r'/\\*.*?\\*/', '', content, flags=re.DOTALL)\n",
    "    \n",
    "    # Remove trailing commas before closing brackets/braces\n",
    "    content = re.sub(r',\\s*([}\\]])', r'\\1', content)\n",
    "    \n",
    "    return json.loads(content)\n",
    "\n",
    "def load_json(filepath):\n",
    "    \"\"\"Load regular JSON file\"\"\"\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def load_any(filepath):\n",
    "    \"\"\"Load either JSON or JSONC file based on extension\"\"\"\n",
    "    if filepath.endswith('.jsonc'):\n",
    "        return load_jsonc(filepath)\n",
    "    else:\n",
    "        return load_json(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bdfc5e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amd_sim_data                   parameters keys: dict_keys(['rr', 'f', 'i', 'age_weights', 'ages', 'p', 'r', 'pf', 'X'])\n",
      "amd_sim_data_Early             parameters keys: dict_keys(['rr', 'f', 'i', 'age_weights', 'ages', 'p', 'r', 'pf', 'X'])\n",
      "amd_sim_data_Intermediate      parameters keys: dict_keys(['rr', 'f', 'i', 'age_weights', 'ages', 'p', 'r', 'pf', 'X'])\n",
      "amd_sim_data_Late-dry          parameters keys: dict_keys(['rr', 'f', 'i', 'age_weights', 'ages', 'p', 'r', 'pf', 'X'])\n",
      "amd_sim_data_Late-wet          parameters keys: dict_keys(['rr', 'f', 'i', 'age_weights', 'ages', 'p', 'r', 'pf', 'X'])\n"
     ]
    }
   ],
   "source": [
    "# TASK 1: relocate age_weights to parameters.jsonc file\n",
    "input_dir = './input_data'\n",
    "stage_dirs = ['amd_sim_data', 'amd_sim_data_Early', 'amd_sim_data_Intermediate', 'amd_sim_data_Late-dry', 'amd_sim_data_Late-wet']\n",
    "\n",
    "for stage_dir in stage_dirs:\n",
    "    parameters = load_jsonc(f'{input_dir}/{stage_dir}/parameters.jsonc')\n",
    "    print(f'{stage_dir:<30} parameters keys: {parameters.keys()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "97c4128b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows: 207\n",
      "number of unique location_id: 18\n",
      "--------------------------------\n",
      "number of nodes: 233\n",
      "number of edges: 232\n"
     ]
    }
   ],
   "source": [
    "# TASK 2: update Load based on region_id_graph\n",
    "stage_dirs = ['amd_sim_data', 'amd_sim_data_Early', 'amd_sim_data_Intermediate', 'amd_sim_data_Late-dry', 'amd_sim_data_Late-wet']\n",
    "stage = stage_dirs[2] # Intermediate\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------#\n",
    "# Read input data\n",
    "\n",
    "input_data = pd.read_csv(f'{input_dir}/{stage}/input_data.csv')\n",
    "output_template = pd.read_csv(f'{input_dir}/{stage}/output_template.csv')\n",
    "parameters = load_any(f'{input_dir}/{stage}/parameters.jsonc')    # dict. {'p': {}, 'age_weights': [], 'ages: []}\n",
    "hierarchy = load_any(f'{input_dir}/{stage}/hierarchy.json')       # dict of lists. {'nodes': [], 'edges': []}\n",
    "nodes_to_fit = load_any(f'{input_dir}/{stage}/nodes_to_fit.json') # LIST of strings\n",
    "\n",
    "print(f'number of rows: {len(input_data)}')\n",
    "print(f'number of unique location_id: {input_data[\"location_id\"].nunique()}')\n",
    "print('--------------------------------')\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------#\n",
    "# Create region_graph\n",
    "nodes = hierarchy['nodes']\n",
    "name_to_id = {} # warning: this does not handle duplicate names\n",
    "id_to_name = {}\n",
    "\n",
    "region_id_graph = nx.DiGraph()\n",
    "\n",
    "for node in nodes:\n",
    "  name_to_id[node[0]] = node[1]['location_id']\n",
    "  id_to_name[node[1]['location_id']] = node[0]\n",
    "\n",
    "  # create region_id_graph\n",
    "  region_id_graph.add_node(node[1]['location_id'])\n",
    "\n",
    "  my_id = node[1]['location_id']\n",
    "  parent_id = node[1]['parent_id']\n",
    "  if my_id != parent_id: # if my_id is not the root node\n",
    "    region_id_graph.add_edge(parent_id, my_id)\n",
    "\n",
    "print(f\"number of nodes: {region_id_graph.number_of_nodes()}\") \n",
    "print(f\"number of edges: {region_id_graph.number_of_edges()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1cba1b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'United States Virgin Islands'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_name[422] # IDs are not incremental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "826289aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204\n",
      "21\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "# TASK 3: define \"coords\"\n",
    "\n",
    "country_list = []\n",
    "region_list = []\n",
    "super_region_list = []\n",
    "\n",
    "for node in hierarchy['nodes']:\n",
    "  if node[1]['level'] == 3:\n",
    "    country_list.append(node[1]['location_id'])\n",
    "  elif node[1]['level'] == 2:\n",
    "    region_list.append(node[1]['location_id'])\n",
    "  elif node[1]['level'] == 1:\n",
    "    super_region_list.append(node[1]['location_id'])\n",
    "    \n",
    "coords = {\n",
    "    \"country\":      country_list,\n",
    "    \"region\":       region_list,\n",
    "    \"super_region\": super_region_list,\n",
    "}\n",
    "\n",
    "print(len(country_list))\n",
    "print(len(region_list))\n",
    "print(len(super_region_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "590211ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area</th>\n",
       "      <th>location_id</th>\n",
       "      <th>stage</th>\n",
       "      <th>stage_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>sex_id</th>\n",
       "      <th>year_id</th>\n",
       "      <th>age_start</th>\n",
       "      <th>age_end</th>\n",
       "      <th>effective_sample_size</th>\n",
       "      <th>value</th>\n",
       "      <th>standard_error</th>\n",
       "      <th>x_sdi</th>\n",
       "      <th>x_tob</th>\n",
       "      <th>data_type</th>\n",
       "      <th>upper_ci</th>\n",
       "      <th>lower_ci</th>\n",
       "      <th>age_weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Netherlands</td>\n",
       "      <td>89</td>\n",
       "      <td>Intermediate</td>\n",
       "      <td>5</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>1990</td>\n",
       "      <td>55</td>\n",
       "      <td>64</td>\n",
       "      <td>1418.0</td>\n",
       "      <td>0.040903</td>\n",
       "      <td>0.005260</td>\n",
       "      <td>0.794612</td>\n",
       "      <td>0.434156</td>\n",
       "      <td>p</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Netherlands</td>\n",
       "      <td>89</td>\n",
       "      <td>Intermediate</td>\n",
       "      <td>5</td>\n",
       "      <td>Female</td>\n",
       "      <td>2</td>\n",
       "      <td>1990</td>\n",
       "      <td>55</td>\n",
       "      <td>64</td>\n",
       "      <td>1802.0</td>\n",
       "      <td>0.033851</td>\n",
       "      <td>0.004260</td>\n",
       "      <td>0.794612</td>\n",
       "      <td>0.383810</td>\n",
       "      <td>p</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Netherlands</td>\n",
       "      <td>89</td>\n",
       "      <td>Intermediate</td>\n",
       "      <td>5</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>1990</td>\n",
       "      <td>65</td>\n",
       "      <td>74</td>\n",
       "      <td>1382.0</td>\n",
       "      <td>0.072359</td>\n",
       "      <td>0.006969</td>\n",
       "      <td>0.794612</td>\n",
       "      <td>0.434156</td>\n",
       "      <td>p</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Netherlands</td>\n",
       "      <td>89</td>\n",
       "      <td>Intermediate</td>\n",
       "      <td>5</td>\n",
       "      <td>Female</td>\n",
       "      <td>2</td>\n",
       "      <td>1990</td>\n",
       "      <td>65</td>\n",
       "      <td>74</td>\n",
       "      <td>1865.0</td>\n",
       "      <td>0.036997</td>\n",
       "      <td>0.004371</td>\n",
       "      <td>0.794612</td>\n",
       "      <td>0.383810</td>\n",
       "      <td>p</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Netherlands</td>\n",
       "      <td>89</td>\n",
       "      <td>Intermediate</td>\n",
       "      <td>5</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>1990</td>\n",
       "      <td>75</td>\n",
       "      <td>84</td>\n",
       "      <td>796.0</td>\n",
       "      <td>0.103015</td>\n",
       "      <td>0.010774</td>\n",
       "      <td>0.794612</td>\n",
       "      <td>0.434156</td>\n",
       "      <td>p</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          area  location_id         stage  stage_id     sex  sex_id  year_id   \n",
       "0  Netherlands           89  Intermediate         5    Male       1     1990  \\\n",
       "1  Netherlands           89  Intermediate         5  Female       2     1990   \n",
       "2  Netherlands           89  Intermediate         5    Male       1     1990   \n",
       "3  Netherlands           89  Intermediate         5  Female       2     1990   \n",
       "4  Netherlands           89  Intermediate         5    Male       1     1990   \n",
       "\n",
       "   age_start  age_end  effective_sample_size     value  standard_error   \n",
       "0         55       64                 1418.0  0.040903        0.005260  \\\n",
       "1         55       64                 1802.0  0.033851        0.004260   \n",
       "2         65       74                 1382.0  0.072359        0.006969   \n",
       "3         65       74                 1865.0  0.036997        0.004371   \n",
       "4         75       84                  796.0  0.103015        0.010774   \n",
       "\n",
       "      x_sdi     x_tob data_type  upper_ci  lower_ci  age_weights  \n",
       "0  0.794612  0.434156         p       NaN       NaN          NaN  \n",
       "1  0.794612  0.383810         p       NaN       NaN          NaN  \n",
       "2  0.794612  0.434156         p       NaN       NaN          NaN  \n",
       "3  0.794612  0.383810         p       NaN       NaN          NaN  \n",
       "4  0.794612  0.434156         p       NaN       NaN          NaN  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Utilizes id_to_name to print the name of the location\n",
    "def describe():\n",
    "        G = region_id_graph\n",
    "        df = input_data\n",
    "        for n in nx.dfs_postorder_nodes(G, 1):\n",
    "            cnt = df['location_id'].eq(n).sum() + sum(G.nodes[c].get('cnt', 0) for c in G.successors(n))\n",
    "            G.nodes[n]['cnt'] = int(cnt)\n",
    "            G.nodes[n]['depth'] = nx.shortest_path_length(G, 1, n)\n",
    "            \n",
    "        for n in nx.dfs_preorder_nodes(G, 1):\n",
    "            if G.nodes[n]['cnt'] > 0:\n",
    "                print('  '*G.nodes[n]['depth'] + id_to_name[n], G.nodes[n]['cnt'])\n",
    "\n",
    "# describe()\n",
    "\n",
    "def keep():\n",
    "    pass\n",
    "    # Suggestion: filter input_data during \"LOAD\"\n",
    "\n",
    "def filter_input_data_by_data_type(input_data: pd.DataFrame, data_type: str) -> pd.DataFrame:\n",
    "        if not input_data.empty:\n",
    "            return input_data[input_data['data_type'] == data_type]\n",
    "        return input_data\n",
    "\n",
    "# since our input_data only has 'p' data, this will return the same input_data\n",
    "filter_input_data_by_data_type(input_data, 'p').head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8b5d9f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process.asr() | parameters\n",
    "# ------------------------------------------------------------\n",
    "data_type                = 'p'\n",
    "reference_area           = 'Global'\n",
    "reference_sex            = 'Both'\n",
    "reference_year           = 'all'\n",
    "mu_age                   = None\n",
    "mu_age_parent            = None\n",
    "sigma_age_parent         = None\n",
    "rate_type                = 'neg_binom'\n",
    "lower_bound              = None\n",
    "interpolation_method     = 'linear'\n",
    "include_covariates       = True\n",
    "zero_re                  = False\n",
    "# ------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7dc3ce0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process.asr() | local variables\n",
    "# ------------------------------------------------------------\n",
    "pm_model = pm.Model()\n",
    "\n",
    "ages = np.array(parameters['ages'])\n",
    "data = filter_input_data_by_data_type(input_data, data_type)\n",
    "lb_data =filter_input_data_by_data_type(input_data, lower_bound) if lower_bound else None\n",
    "params_of_data_type = parameters.get(data_type, {})\n",
    "\n",
    "variables = {}\n",
    "variables['data'] = data # TODO-variables\n",
    "\n",
    "# check: mu_age_parent & sigma_age_parent\n",
    "#  if either mu_age_parent or sigma_age_parent is NaN, set them to None\n",
    "if (isinstance(mu_age_parent, np.ndarray) and np.isnan(mu_age_parent).any()) or \\\n",
    "    (isinstance(sigma_age_parent, np.ndarray) and np.isnan(sigma_age_parent).any()):\n",
    "\n",
    "    mu_age_parent = None\n",
    "    sigma_age_parent = None\n",
    "# ------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "449ad149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process.asr() | [1] Prepare spline.spline (knots, smoothing)\n",
    "# ------------------------------------------------------------\n",
    "knots = np.array(params_of_data_type.get('parameter_age_mesh', np.arange(ages[0], ages[-1] + 1, 5)))\n",
    "\n",
    "\n",
    "smooth_map = {'No Prior': np.inf, 'Slightly': 0.5, 'Moderately': 0.05, 'Very': 0.005}\n",
    "smoothness_param = params_of_data_type.get('smoothness')\n",
    "\n",
    "if isinstance(smoothness_param, dict): \n",
    "    amount = smoothness_param.get('amount')\n",
    "\n",
    "    if isinstance(amount, (int, float)): # smoothness_param is dict, and amount is int or float\n",
    "        smoothing = float(amount)\n",
    "    else:                                # smoothness_param is dict, and amount may be string\n",
    "        smoothing = smooth_map.get(amount, 0.0)\n",
    "\n",
    "else:                                    # smoothness_param may be string\n",
    "    smoothing = smooth_map.get(smoothness_param, 0.0)\n",
    "# ------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568a0bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process.asr() | [2] Spline knots & smoothing\n",
    "\n",
    "\n",
    "    smoothness_param = parameters.get('smoothness')\n",
    "    \n",
    "\n",
    "\n",
    "# \"smoothness\": {\n",
    "#       \"age_start\": 2, // smoothing begins\n",
    "#       \"amount\": \"Slightly\", // smoothing intensity\n",
    "#       \"age_end\": 94, // smoothing ends\n",
    "#     },"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9b72f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process.asr() | [3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71be6de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# process.asr() | [4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e8c6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### BELOW IS ORIGINAL CODE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed4a9693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Level 3: country\n",
    "countries = (\n",
    "    hier[hier[\"Level\"] == 3]\n",
    "    .rename(columns={\n",
    "        \"Location ID\": \"loc3_id\",\n",
    "        \"Location Name\": \"country\",\n",
    "        \"Parent ID\": \"parent2_id\"\n",
    "    })\n",
    "    [[\"loc3_id\", \"country\", \"parent2_id\"]]\n",
    ")\n",
    "\n",
    "# Level 2: region\n",
    "regions = (\n",
    "    hier[hier[\"Level\"] == 2]\n",
    "    .rename(columns={\n",
    "        \"Location ID\": \"loc2_id\",\n",
    "        \"Location Name\": \"region\",\n",
    "        \"Parent ID\": \"parent1_id\"\n",
    "    })\n",
    "    [[\"loc2_id\", \"region\", \"parent1_id\"]]\n",
    ")\n",
    "\n",
    "# Level 1: super-region\n",
    "superregs = (\n",
    "    hier[hier[\"Level\"] == 1]\n",
    "    .rename(columns={\n",
    "        \"Location ID\": \"loc1_id\",\n",
    "        \"Location Name\": \"super_region\"\n",
    "    })\n",
    "    [[\"loc1_id\", \"super_region\"]]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc9e0ad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>region</th>\n",
       "      <th>super_region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>High-income</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United States of America</td>\n",
       "      <td>High-income North America</td>\n",
       "      <td>High-income</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Israel</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>High-income</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Switzerland</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>High-income</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Canada</td>\n",
       "      <td>High-income North America</td>\n",
       "      <td>High-income</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    country                     region super_region\n",
       "0                    Sweden             Western Europe  High-income\n",
       "1  United States of America  High-income North America  High-income\n",
       "3                    Israel             Western Europe  High-income\n",
       "5               Switzerland             Western Europe  High-income\n",
       "7                    Canada  High-income North America  High-income"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4.1 country 정보 붙이기\n",
    "df = df.merge(countries, on=\"country\", how=\"left\")\n",
    "\n",
    "# 4.2 region 정보 붙이기\n",
    "df = df.merge(\n",
    "    regions,\n",
    "    left_on=\"parent2_id\",\n",
    "    right_on=\"loc2_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# 4.3 super-region 정보 붙이기\n",
    "df = df.merge(\n",
    "    superregs,\n",
    "    left_on=\"parent1_id\",\n",
    "    right_on=\"loc1_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# 확인\n",
    "df[[\"country\",\"region\",\"super_region\"]].drop_duplicates().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6de9264e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     study                   country  \\\n",
      "0   Nilsson LV et al, 1984                    Sweden   \n",
      "1     Kramer M et al, 1985  United States of America   \n",
      "2    Flament M et al, 1990  United States of America   \n",
      "3     Zohar AH et al, 1992                    Israel   \n",
      "4  Reinherz HZ et al, 1993  United States of America   \n",
      "\n",
      "                      region super_region  age_code  meth_code  prev_code  \\\n",
      "0             Western Europe  High-income         1          0          0   \n",
      "1  High-income North America  High-income         1          0          0   \n",
      "2  High-income North America  High-income         1          0          0   \n",
      "3             Western Europe  High-income         0          0          0   \n",
      "4  High-income North America  High-income         0          0          0   \n",
      "\n",
      "   prevalence_value  \n",
      "0              98.0  \n",
      "1              22.0  \n",
      "2              55.0  \n",
      "3              36.0  \n",
      "4              21.0  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2) 매핑 딕셔너리\n",
    "age_map  = {\"Children\":0, \"Adult\":1, \"Both\":2}\n",
    "meth_map = {\n",
    "    \"Interview based\":0,\n",
    "    \"Non-interview\":1\n",
    "}\n",
    "prev_map = {\n",
    "    \"point prevalence\":     0,\n",
    "    \"12-month prevalence\":  1,\n",
    "    \"life-time prevalence\": 2\n",
    "}\n",
    "\n",
    "# 3) long 포맷으로 전환\n",
    "df_long = df.melt(\n",
    "    id_vars=[\n",
    "        \"study\",             \n",
    "        \"country\",\n",
    "        \"region\",\n",
    "        \"super_region\",\n",
    "        \"Methods of questionnaire\",\n",
    "        \"Age range\",\n",
    "        \"study population\"\n",
    "    ],\n",
    "    value_vars=[\n",
    "        \"point prevalence\",\n",
    "        \"12-month prevalence\",\n",
    "        \"life-time prevalence\"\n",
    "    ],\n",
    "    var_name=\"prevalence_type\",\n",
    "    value_name=\"prevalence_value\"\n",
    ").dropna(subset=[\"prevalence_value\"])\n",
    "\n",
    "# 4) 코드 매핑\n",
    "df_long[\"age_code\"]  = df_long[\"Age range\"].map(age_map)\n",
    "df_long[\"meth_code\"] = df_long[\"Methods of questionnaire\"].map(meth_map)\n",
    "df_long[\"prev_code\"] = df_long[\"prevalence_type\"].map(prev_map)\n",
    "\n",
    "# 5) 최종 확인\n",
    "result = df_long[[\n",
    "    \"study\", \"country\", \"region\", \"super_region\",\n",
    "    \"age_code\", \"meth_code\",\n",
    "    \"prev_code\", \"prevalence_value\"\n",
    "]]\n",
    "print(result.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca0029bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) 비율(p_hat) 및 로그 변환\n",
    "#    prevalence_value: point/12-month/life-time 케이스 수\n",
    "#    study population: 전체 표본 수\n",
    "\n",
    "# 6.1 p_hat 계산\n",
    "df_long[\"p_hat\"] = df_long[\"prevalence_value\"] / df_long[\"study population\"]\n",
    "\n",
    "# 6.2 로그 변환 (필요 시 0 회피를 위해 clamp)\n",
    "eps = 1e-6\n",
    "df_long[\"p_hat\"] = df_long[\"p_hat\"].clip(eps, 1 - eps)\n",
    "df_long[\"log_p_hat\"] = np.log(df_long[\"p_hat\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe5e535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study</th>\n",
       "      <th>prevalence_type</th>\n",
       "      <th>multi_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nilsson LV et al, 1984</td>\n",
       "      <td>point prevalence</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kramer M et al, 1985</td>\n",
       "      <td>point prevalence</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Flament M et al, 1990</td>\n",
       "      <td>point prevalence</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Zohar AH et al, 1992</td>\n",
       "      <td>point prevalence</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reinherz HZ et al, 1993</td>\n",
       "      <td>point prevalence</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     study   prevalence_type  multi_mask\n",
       "0   Nilsson LV et al, 1984  point prevalence           0\n",
       "1     Kramer M et al, 1985  point prevalence           0\n",
       "2    Flament M et al, 1990  point prevalence           1\n",
       "3     Zohar AH et al, 1992  point prevalence           0\n",
       "4  Reinherz HZ et al, 1993  point prevalence           0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) df_long 이용: prevalence_type 당 개수 세기\n",
    "prev_count = df_long.groupby(\"study\")[\"prevalence_type\"] \\\n",
    "                    .transform(\"nunique\")\n",
    "\n",
    "# 2) 2개 이상이면 1, 아니면 0\n",
    "df_long[\"multi_mask\"] = (prev_count >= 2).astype(int)\n",
    "\n",
    "# 3) 확인\n",
    "df_long[[\"study\",\"prevalence_type\",\"multi_mask\"]].drop_duplicates().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ecf578c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1) hierarchy 에서 좌표(리스트) 직접 추출\n",
    "# level 1 → super_region (7개)\n",
    "super_list = (\n",
    "    hier[hier[\"Level\"] == 1]\n",
    "    [\"Location Name\"]\n",
    "    .tolist()\n",
    ")\n",
    "\n",
    "# level 2 → region (21개)\n",
    "region_list = (\n",
    "    hier[hier[\"Level\"] == 2]\n",
    "    [\"Location Name\"]\n",
    "    .tolist()\n",
    ")\n",
    "\n",
    "# level 3 → country (180+개)\n",
    "country_list = (\n",
    "    hier[hier[\"Level\"] == 3]\n",
    "    [\"Location Name\"]\n",
    "    .tolist()\n",
    ")\n",
    "\n",
    "# 2) coords 정의 (unchanged)\n",
    "coords = {\n",
    "    \"country\":      country_list,\n",
    "    \"region\":       region_list,\n",
    "    \"super_region\": super_list,\n",
    "    \"age\":          [\"Children\", \"Adult\", \"Both\"],\n",
    "    \"meth\":         [\"Interview based\", \"Non-interview\"],\n",
    "    \"prev\":         [\"point prevalence\", \"12-month prevalence\", \"life-time prevalence\"],\n",
    "    \"study\":        df_long[\"study\"].unique().tolist()\n",
    "}\n",
    "\n",
    "# 3) questionnaire method 컬럼명 변경 반영\n",
    "#    이미 엑셀에서 \"Methods of questionnaire\" 아래 값을 \"Interview based\" / \"Non-interview\"로 바꿔 두셨다면\n",
    "meth_map = {\n",
    "    \"Interview based\":    0,\n",
    "    \"Non-interview\":      1\n",
    "}\n",
    "df_long[\"meth_code\"] = df_long[\"Methods of questionnaire\"].map(meth_map)\n",
    "\n",
    "# 4) index 배열 생성\n",
    "country_idx = pd.Categorical(\n",
    "    df_long[\"country\"],\n",
    "    categories=coords[\"country\"]\n",
    ").codes\n",
    "\n",
    "region_idx = pd.Categorical(\n",
    "    df_long[\"region\"],\n",
    "    categories=coords[\"region\"]\n",
    ").codes\n",
    "\n",
    "super_idx = pd.Categorical(\n",
    "    df_long[\"super_region\"],\n",
    "    categories=coords[\"super_region\"]\n",
    ").codes\n",
    "\n",
    "age_idx   = df_long[\"age_code\"].to_numpy()\n",
    "meth_idx  = df_long[\"meth_code\"].to_numpy()         \n",
    "prev_idx  = df_long[\"prev_code\"].to_numpy()\n",
    "\n",
    "study_idx = pd.Categorical(\n",
    "    df_long[\"study\"],\n",
    "    categories=coords[\"study\"]\n",
    ").codes\n",
    "\n",
    "# 5) mask / 관측치 벡터 (unchanged)\n",
    "multi_mask = df_long[\"multi_mask\"].to_numpy()\n",
    "y_obs      = df_long[\"log_p_hat\"].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203c1bac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffa9cf9e5a5442c7ad3bebb3b8c6c0fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finished [100%]: Average Loss = 395.52\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [β0, β_age, β_meth, β_prev, σ_sr, η_sr, σ_r, η_r, σ_c, η_c, σ_prev_study, η_prev_study, σ_y]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b22a72e62f74df98ebde817413195c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 500 tune and 1_000 draw iterations (2_000 + 4_000 draws total) took 7188 seconds.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "plot_forest() got an unexpected keyword argument 'credible_interval'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 58\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;66;03m# ─── forest plot 으로 깔끔하게 시각화 ───\u001b[39;00m\n\u001b[0;32m     57\u001b[0m az\u001b[38;5;241m.\u001b[39mstyle\u001b[38;5;241m.\u001b[39muse(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marviz-darkgrid\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 58\u001b[0m \u001b[43maz\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_forest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43midata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvar_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mβ_age\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mβ_meth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mβ_prev\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mσ_sr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mσ_r\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mσ_c\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mσ_prev_study\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mσ_y\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcombined\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcredible_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.95\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mridgeplot_overlap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\n\u001b[0;32m     64\u001b[0m \u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: plot_forest() got an unexpected keyword argument 'credible_interval'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with pm.Model(coords=coords) as model:\n",
    "\n",
    "    # ─── Fixed effects ───\n",
    "    β0    = pm.Normal(\"β0\",    mu=0, sigma=10)\n",
    "    β_age = pm.Normal(\"β_age\", mu=0, sigma=5, dims=\"age\")\n",
    "    β_meth= pm.Normal(\"β_meth\",mu=0, sigma=5, dims=\"meth\")\n",
    "    β_prev= pm.Normal(\"β_prev\",mu=0, sigma=5, dims=\"prev\")\n",
    "\n",
    "    # ─── Non-centered random intercepts ───\n",
    "    σ_sr = pm.HalfNormal(\"σ_sr\", sigma=5)\n",
    "    η_sr = pm.Normal(\"η_sr\", mu=0, sigma=1, dims=\"super_region\")\n",
    "    u_sr = pm.Deterministic(\"u_sr\", η_sr * σ_sr)\n",
    "\n",
    "    σ_r  = pm.HalfNormal(\"σ_r\", sigma=5)\n",
    "    η_r  = pm.Normal(\"η_r\",  mu=0, sigma=1, dims=\"region\")\n",
    "    u_r  = pm.Deterministic(\"u_r\", η_r * σ_r)\n",
    "\n",
    "    σ_c  = pm.HalfNormal(\"σ_c\", sigma=5)\n",
    "    η_c  = pm.Normal(\"η_c\",  mu=0, sigma=1, dims=\"country\")\n",
    "    u_c  = pm.Deterministic(\"u_c\", η_c * σ_c)\n",
    "\n",
    "    # ─── Study-level random slope (non-centered) ───\n",
    "    σ_ps= pm.HalfNormal(\"σ_prev_study\", sigma=5)\n",
    "    η_ps= pm.Normal(\"η_prev_study\", mu=0, sigma=1, dims=(\"study\",\"prev\"))\n",
    "    u_ps= pm.Deterministic(\"u_prev_study\", η_ps * σ_ps)\n",
    "\n",
    "    # ─── 선형 예측식 μ ───\n",
    "    prev_effect = (β_prev[prev_idx] + u_ps[study_idx,prev_idx]) * multi_mask\n",
    "\n",
    "    μ = (\n",
    "        β0\n",
    "        + β_age[age_idx]\n",
    "        + β_meth[meth_idx]\n",
    "        + prev_effect\n",
    "        + u_sr[super_idx]\n",
    "        + u_r[region_idx]\n",
    "        + u_c[country_idx]\n",
    "    )\n",
    "\n",
    "    # ─── 관측모형 ───\n",
    "    σ_y = pm.HalfNormal(\"σ_y\", sigma=1)\n",
    "    pm.Normal(\"y\", mu=μ, sigma=σ_y, observed=y_obs)\n",
    "\n",
    "    # ─── (옵션) ADVI 워밍업 — 빠르게 근사 posterior 생성 ───\n",
    "    advi = pm.fit(method=\"advi\", n=5000)\n",
    "\n",
    "    # ─── NUTS 샘플링 ───\n",
    "    idata = pm.sample(\n",
    "        draws=1000, tune=500,\n",
    "        chains=4, cores=4,\n",
    "        target_accept=0.95,\n",
    "        max_treedepth=15,\n",
    "        progressbar=\"split\"\n",
    "    )\n",
    "\n",
    "# ─── forest plot 으로 깔끔하게 시각화 ───\n",
    "az.style.use(\"arviz-darkgrid\")\n",
    "az.plot_forest(\n",
    "    idata,\n",
    "    var_names=[\"β_age\",\"β_meth\",\"β_prev\",\"σ_sr\",\"σ_r\",\"σ_c\",\"σ_prev_study\",\"σ_y\"],\n",
    "    combined=True,\n",
    "    credible_interval=0.95,\n",
    "    ridgeplot_overlap=0.5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76eca402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               mean     sd  hdi_2.5%  hdi_97.5%  mcse_mean  \\\n",
      "β0                           -3.537  4.085   -11.136      4.469      0.111   \n",
      "β_age[Children]              -0.263  2.759    -5.733      4.756      0.080   \n",
      "β_age[Adult]                 -0.284  2.752    -5.538      4.946      0.080   \n",
      "β_age[Both]                  -0.183  2.763    -5.575      4.984      0.080   \n",
      "β_meth[Interview based]       0.241  3.283    -6.431      6.356      0.080   \n",
      "β_meth[Non-interview]        -0.924  3.280    -7.457      5.359      0.080   \n",
      "β_prev[point prevalence]     -1.014  0.388    -1.760     -0.244      0.006   \n",
      "β_prev[12-month prevalence]  -0.401  0.291    -0.957      0.177      0.006   \n",
      "β_prev[life-time prevalence] -0.121  0.290    -0.680      0.434      0.006   \n",
      "σ_sr                          0.916  0.575     0.008      1.955      0.017   \n",
      "σ_r                           0.291  0.242     0.000      0.755      0.008   \n",
      "σ_c                           0.455  0.218     0.011      0.816      0.010   \n",
      "σ_prev_study                  0.182  0.139     0.000      0.449      0.003   \n",
      "σ_y                           0.881  0.080     0.731      1.039      0.002   \n",
      "\n",
      "                              mcse_sd  ess_bulk  ess_tail  r_hat  \n",
      "β0                              0.059  1349.819  2156.025  1.001  \n",
      "β_age[Children]                 0.042  1195.568  1998.628  1.002  \n",
      "β_age[Adult]                    0.042  1198.977  1947.445  1.002  \n",
      "β_age[Both]                     0.042  1187.404  1955.283  1.003  \n",
      "β_meth[Interview based]         0.047  1672.714  2359.159  1.001  \n",
      "β_meth[Non-interview]           0.047  1664.701  2388.832  1.002  \n",
      "β_prev[point prevalence]        0.006  3568.001  2825.607  1.001  \n",
      "β_prev[12-month prevalence]     0.004  2734.519  2586.475  1.001  \n",
      "β_prev[life-time prevalence]    0.004  2495.347  2760.945  1.001  \n",
      "σ_sr                            0.016   851.519   857.021  1.007  \n",
      "σ_r                             0.007  1035.500  1252.875  1.007  \n",
      "σ_c                             0.004   501.880   695.262  1.008  \n",
      "σ_prev_study                    0.002  1607.233  1519.844  1.001  \n",
      "σ_y                             0.001  1135.781  2415.758  1.002  \n"
     ]
    }
   ],
   "source": [
    "import arviz as az\n",
    "\n",
    "# idata는 이미 pm.sample()의 결과\n",
    "summary_df = az.summary(\n",
    "    idata,\n",
    "    var_names=[\n",
    "        \"β0\", \"β_age\", \"β_meth\", \"β_prev\",\n",
    "        \"σ_sr\", \"σ_r\", \"σ_c\", \"σ_prev_study\", \"σ_y\"\n",
    "    ],\n",
    "    round_to=3,         # 소수점 자리수\n",
    "    hdi_prob=0.95       # 95% 신뢰구간\n",
    ")\n",
    "print(summary_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a21a0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to C:/Users/정이든/Desktop/연구실/9. prevalence of OCD/3차 와꾸/life_time_prevalence.xlsx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 1) posterior를 (chain, draw) → sample 차원 하나로 합치기\n",
    "post = idata.posterior.stack(sample=(\"chain\",\"draw\"))\n",
    "\n",
    "# 2) coords에 저장된 리스트 불러오기\n",
    "country_list      = coords[\"country\"]       # Level-3 국가 이름 리스트\n",
    "super_list        = coords[\"super_region\"]  # Level-1 슈퍼리전\n",
    "region_list       = coords[\"region\"]        # Level-2 리전\n",
    "age_list          = coords[\"age\"]           # [\"Children\",\"Adult\",\"Both\"]\n",
    "meth_list         = coords[\"meth\"]          # [\"Interview based\",\"Non-interview\"]\n",
    "prev_list         = coords[\"prev\"]          # [\"point prevalence\",\"12-month prevalence\",\"life-time prevalence\"]\n",
    "\n",
    "# 3) 관심 범주의 posterior 샘플 꺼내기\n",
    "β0_samps         = post[\"β0\"].values                             # (samples,)\n",
    "β_age_Both       = post[\"β_age\"].sel(age=\"Both\").values          # (samples,)\n",
    "β_meth_IB        = post[\"β_meth\"].sel(meth=\"Interview based\").values  # (samples,)\n",
    "β_prev_life      = post[\"β_prev\"].sel(prev=\"life-time prevalence\").values  # (samples,)\n",
    "\n",
    "u_sr_samps       = post[\"u_sr\"].values      # (super_region, samples)\n",
    "u_r_samps        = post[\"u_r\"].values       # (region, samples)\n",
    "u_c_samps        = post[\"u_c\"].values       # (country, samples)\n",
    "\n",
    "# 4) country → region, super_region 매핑 (levels 파일에서 미리 만들어 두었다면 그것 사용)\n",
    "#    여기선 hier 데이터프레임에 있는 Level, Location Name, Parent ID 이용\n",
    "mapping = hier[[\"Level\",\"Location ID\",\"Location Name\",\"Parent ID\"]]\n",
    "# Level3\n",
    "lvl3 = mapping[mapping[\"Level\"]==3].rename(columns={\n",
    "    \"Location Name\":\"country\",\"Location ID\":\"loc3\",\"Parent ID\":\"parent2\"\n",
    "})\n",
    "# Level2\n",
    "lvl2 = mapping[mapping[\"Level\"]==2].rename(columns={\n",
    "    \"Location Name\":\"region\",\"Location ID\":\"loc2\",\"Parent ID\":\"parent1\"\n",
    "})\n",
    "# Level1\n",
    "lvl1 = mapping[mapping[\"Level\"]==1].rename(columns={\n",
    "    \"Location Name\":\"super_region\",\"Location ID\":\"loc1\"\n",
    "})\n",
    "\n",
    "# merge to get each country’s region & super_region names\n",
    "df_map = (\n",
    "    lvl3[[\"country\",\"loc3\",\"parent2\"]]\n",
    "    .merge(lvl2[[\"loc2\",\"region\",\"parent1\"]], left_on=\"parent2\", right_on=\"loc2\", how=\"left\")\n",
    "    .merge(lvl1[[\"loc1\",\"super_region\"]], left_on=\"parent1\", right_on=\"loc1\", how=\"left\")\n",
    "    [[\"country\",\"region\",\"super_region\"]]\n",
    ")\n",
    "\n",
    "# 5) Monte Carlo 샘플마다 μ 계산 → p = exp(μ)\n",
    "results = []\n",
    "n_samps = β0_samps.shape[0]\n",
    "for idx, row in df_map.iterrows():\n",
    "    country    = row[\"country\"]\n",
    "    region     = row[\"region\"]\n",
    "    super_reg  = row[\"super_region\"]\n",
    "    i_sr = super_list.index(super_reg)\n",
    "    i_r  = region_list.index(region)\n",
    "    i_c  = country_list.index(country)\n",
    "\n",
    "    # μ 샘플 벡터\n",
    "    mu = (\n",
    "        β0_samps\n",
    "        + β_age_Both\n",
    "        + β_meth_IB\n",
    "        + β_prev_life\n",
    "        + u_sr_samps[i_sr, :]\n",
    "        + u_r_samps[i_r, :]\n",
    "        + u_c_samps[i_c, :]\n",
    "    )\n",
    "    # prevalence 비율로 변환\n",
    "    p = np.exp(mu)\n",
    "\n",
    "    # median & 95% HDI\n",
    "    med = np.median(p)\n",
    "    hdi_lo, hdi_hi = az.hdi(p, hdi_prob=0.95)\n",
    "\n",
    "    results.append({\n",
    "        \"country\":             country,\n",
    "        \"region\":              region,\n",
    "        \"super_region\":        super_reg,\n",
    "        \"median_life_prev\":    med,\n",
    "        \"hdi_2.5%\":            hdi_lo,\n",
    "        \"hdi_97.5%\":           hdi_hi\n",
    "    })\n",
    "\n",
    "df_out = pd.DataFrame(results)\n",
    "\n",
    "# 6) 엑셀로 저장\n",
    "output_path = \"C:/Users/정이든/Desktop/연구실/9. prevalence of OCD/3차 와꾸/life_time_prevalence.xlsx\"\n",
    "df_out.to_excel(output_path, index=False)\n",
    "print(f\"Saved to {output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
